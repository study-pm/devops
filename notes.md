<link href="styles.css" rel="stylesheet">

# МДК.04.01 Внедрение и поддержка программного обеспечения компьютерных систем
6735e93d5040133e8429e656

- [Изучаем Docker](#изучаем-docker)
  - [Изучаем Docker, часть 1: основы / Хабр](#изучаем-docker-часть-1-основы--хабр)
    - [Метафоры и Docker](#метафоры-и-docker)
    - [Контейнер](#контейнер)
    - [Живые организмы](#живые-организмы)
    - [Программное обеспечение](#программное-обеспечение)
    - [Концепции Docker](#концепции-docker)
      - [▍Виртуальные машины](#виртуальные-машины)
      - [▍Образ контейнера Docker](#образ-контейнера-docker)
      - [▍Файл Dockerfile](#файл-dockerfile)
      - [▍Контейнер Docker](#контейнер-docker)
      - [▍Репозиторий контейнеров](#репозиторий-контейнеров)
    - [Готовим с Docker](#готовим-с-docker)
    - [Итоги](#итоги)
  - [Изучаем Docker, часть 2: термины и концепции / Хабр](#изучаем-docker-часть-2-термины-и-концепции--хабр)
    - [Термины экосистемы Docker](#термины-экосистемы-docker)
    - [Механизмы Docker](#механизмы-docker)
      - [▍Платформа Docker](#платформа-docker)
      - [▍Движок Docker](#движок-docker)
      - [▍Клиент Docker](#клиент-docker)
      - [▍Демон Docker](#демон-docker)
      - [▍Тома Docker](#тома-docker)
      - [▍Реестр Docker](#реестр-docker)
      - [▍Хаб Docker](#хаб-docker)
      - [▍Репозиторий Docker](#репозиторий-docker)
    - [Масштабирование решений, основанных на контейнерах](#масштабирование-решений-основанных-на-контейнерах)
      - [▍Сеть Docker](#сеть-docker)
      - [▍Docker Compose](#docker-compose)
      - [▍Docker Swarm](#docker-swarm)
      - [▍Сервисы Docker](#сервисы-docker)
    - [Краткий перечень терминов](#краткий-перечень-терминов)
    - [Kubernetes](#kubernetes)
    - [Итоги: печём пончики с Docker](#итоги-печём-пончики-с-docker)
  - [Изучаем Docker, часть 3: файлы Dockerfile / Хабр](#изучаем-docker-часть-3-файлы-dockerfile--хабр)
    - [Образы Docker](#образы-docker)
    - [Файлы Dockerfile](#файлы-dockerfile)
    - [Дюжина инструкций Dockerfile](#дюжина-инструкций-dockerfile)
    - [Инструкции и примеры их использования](#инструкции-и-примеры-их-использования)
      - [▍Простой Dockerfile](#простой-dockerfile)
      - [▍Инструкция `FROM`](#инструкция-from)
      - [▍Более сложный Dockerfile](#более-сложный-dockerfile)
      - [▍Инструкция `LABEL`](#инструкция-label)
      - [▍Инструкция `ENV`](#инструкция-env)
      - [▍Инструкция `RUN`](#инструкция-run)
      - [▍Инструкция `COPY`](#инструкция-copy)
      - [▍Инструкция `ADD`](#инструкция-add)
      - [▍Инструкция `CMD`](#инструкция-cmd)
      - [▍Ещё более сложный Dockerfile](#ещё-более-сложный-dockerfile)
      - [▍Инструкция `WORKDIR`](#инструкция-workdir)
      - [▍Инструкция `ARG`](#инструкция-arg)
      - [▍Инструкция ENTRYPOINT](#инструкция-entrypoint)
      - [▍Инструкция `EXPOSE`](#инструкция-expose)
      - [▍Инструкция `VOLUME`](#инструкция-volume)
    - [Итоги](#итоги-1)
  - [Изучаем Docker, часть 4: уменьшение размеров образов и ускорение их сборки / Хабр](#изучаем-docker-часть-4-уменьшение-размеров-образов-и-ускорение-их-сборки--хабр)
    - [Кэширование](#кэширование)
    - [Уменьшение размеров образов](#уменьшение-размеров-образов)
      - [▍Тщательный подбор базового образа](#тщательный-подбор-базового-образа)
      - [▍Многоступенчатая сборка образов](#многоступенчатая-сборка-образов)
      - [▍Файл .dockerignore](#файл-dockerignore)
    - [Исследование размеров образов](#исследование-размеров-образов)
    - [Рекомендации по уменьшению размеров образов и ускорению процесса их сборки](#рекомендации-по-уменьшению-размеров-образов-и-ускорению-процесса-их-сборки)
    - [Итоги](#итоги-2)

## Изучаем Docker
673865ea5040133e8429e66f

Автор [оригинала](https://towardsdatascience.com/learn-enough-docker-to-be-useful-b7ba70caeb4b): Jeff Hale

Технологии контейнеризации приложений нашли широкое применение в сферах разработки ПО и анализа данных. Эти технологии помогают сделать приложения более безопасными, облегчают их развёртывание и улучшают возможности по их масштабированию. Рост и развитие технологий контейнеризации можно считать одним из важнейших трендов современности.

### Изучаем Docker, часть 1: основы / Хабр
[673887bb5040133e8429e675](https://habr.com/ru/companies/ruvds/articles/438796/)

<dfn title="docker">Docker</dfn> — это платформа, которая предназначена для разработки, развёртывания и запуска приложений в контейнерах. Слово «Docker» в последнее время стало чем-то вроде синонима слова «контейнеризация». И если вы ещё не пользуетесь Docker, но при этом работаете или собираетесь работать в сферах разработки приложений или анализа данных, то Docker — это то, с чем вы непременно встретитесь в будущем.

Если вы пока не знаете о том, что такое Docker, сейчас у вас есть шанс сделать первый шаг к пониманию этой платформы. А именно, освоив этот материал, вы разберётесь с основами Docker и попутно приготовите пиццу.

#### Метафоры и Docker

Мы постоянно сталкиваемся с метафорами. Если заглянуть в словарь Ожегова, то окажется, что метафора — это «скрытое образное сравнение, уподобление одного предмета, явления другому». Метафоры помогают нам ухватывать суть новых для нас явлений. Например, виртуальные контейнеры можно сравнить с обычными пластиковыми контейнерами. Такое сравнение, через сопоставление уже известных нам свойств обычных контейнеров со свойствами виртуальных контейнеров, поможет сначала с ними познакомиться, а потом и понять их сущность.

Как вы понимаете, мы собираемся начать разговор о Docker с понятия «контейнер».

#### Контейнер

Как и обычный пластиковый контейнер, контейнер Docker обладает следующими характеристиками:

*[AWS]: Amazon Web Services

1. В нём можно что-то хранить. Нечто может находиться либо в контейнере, либо за его пределами.
2. Его можно переносить. Контейнер Docker можно использовать на локальном компьютере, на компьютере коллеги, на сервере поставщика облачных услуг (вроде AWS). Это роднит контейнеры Docker с обычными контейнерами, в которых, например, перевозят разные милые сердцу безделушки при переезде в новый дом.
3. В контейнер удобно что-то класть и удобно что-то из него вынимать. У обычного контейнера есть крышка на защёлках, которую надо снять для того, чтобы что-то положить в контейнер или что-то из него вынуть. У контейнеров Docker есть нечто подобное, представляющее их интерфейс, то есть — механизмы, позволяющие им взаимодействовать с внешним миром. Например, у контейнера есть порты, которые можно открывать для того, чтобы к приложению, работающему в контейнере, можно было бы обращаться из браузера. Работать с контейнером можно и средствами командной строки.
4. Если вам нужен контейнер, его можно заказать в интернет-магазине. Пустой контейнер можно купить, например, на сайте Amazon. В этот магазин контейнеры попадают от производителей, которые делают их в огромных количествах, используя пресс-формы. В случае с контейнерами Docker то, что можно сравнить с пресс-формой, а именно — образ контейнера, хранится в специальном репозитории. Если вам нужен некий контейнер, вы можете загрузить из репозитория соответствующий образ, и, используя его, этот контейнер создать.

Конечно, пластиковые контейнеры, в отличие от контейнеров Docker, никто вам не будет присылать бесплатно, да и когда вы их получите, они будут пустыми. А вот в контейнерах Docker всегда есть что-то интересное.

#### Живые организмы

Ещё один подход к размышлениям о контейнерах Docker заключается в сравнении их с экземплярами живых организмов. «Экземпляр» — это нечто, существующее в некоей форме. Это не просто код. Это код, который стал причиной существования чего-то большего, чем он сам, чего-то, образно говоря, живого. Как и другие живые организмы, экземпляры контейнеров появляются на свет, живут и умирают.

Контейнеры Docker — это вызванные к жизни образы Docker.

#### Программное обеспечение

Контейнеры Docker можно сравнивать не только с обычными контейнерами или с живыми организмами. Их можно сравнить и с программами. В конце концов, контейнеры — это программы. И, на фундаментальном уровне, контейнер представляет собой набор инструкций, который выполняется на некоем процессоре, обрабатывая какие-то данные.

Во время выполнения контейнера Docker внутри него обычно выполняется какая-то программа. Она выполняет в контейнере некие действия, то есть — делает что-то полезное.

Например, код, который работает в контейнере Docker, возможно, отправил на ваш компьютер тот текст, который вы сейчас читаете. Вполне возможно и то, что именно код, выполняющийся в контейнере Docker, принимает голосовые команды, которые вы даёте Amazon Alexa, и преобразует их в инструкции для ещё каких-нибудь программ, работающих в других контейнерах.

Благодаря использованию Docker можно, на одном и том же компьютере, одновременно запускать множество контейнеров. И, как и любые другие программы, контейнеры Docker можно запускать, останавливать, удалять. Можно исследовать их содержимое и создавать их.

#### Концепции Docker

##### ▍Виртуальные машины

Предшественниками контейнеров Docker были виртуальные машины. Виртуальная машина, как и контейнер, изолирует от внешней среды приложение и его зависимости. Однако контейнеры Docker обладают преимуществами перед виртуальными машинами. Так, они потребляют меньше ресурсов, их очень легко переносить, они быстрее запускаются и приходят в работоспособное состояние. В этом материале можно найти подробное сравнение контейнеров и виртуальных машин.

##### ▍Образ контейнера Docker

Выше мы уже говорили об «образах». Что это такое? Хороший вопрос. То, что в терминологии Docker называется «образом», или, по-английски, «image», это совсем не то же самое, что, например, фотография (это — одно из значений слова «image»).

Образы контейнеров Docker можно сравнить с чертежами, с формочками для печенья, или с пресс-формами для изготовления пластиковых изделий. Образы — это неизменные шаблоны, которые используются для создания одинаковых контейнеров.

В образе контейнера Docker содержится образ базовой операционной системы, код приложения, библиотеки, от которого оно зависит. Всё это скомпоновано в виде единой сущности, на основе которой можно создать контейнер.

##### ▍Файл Dockerfile

Файл [Dockerfile](https://docs.docker.com/reference/dockerfile/) содержит набор инструкций, следуя которым Docker будет собирать образ контейнера. Этот файл содержит описание базового образа, который будет представлять собой исходный слой образа. Среди популярных официальных базовых образов можно отметить [python](https://hub.docker.com/_/python/), [ubuntu](https://hub.docker.com/_/ubuntu), [alpine](https://hub.docker.com/_/alpine).

В образ контейнера, поверх базового образа, можно добавлять дополнительные слои. Делается это в соответствии с инструкциями из *Dockerfile*. Например, если *Dockerfile* описывает образ, который планируется использовать для решения задач машинного обучения, то в нём могут быть инструкции для включения в промежуточный слой такого образа библиотек NumPy, Pandas и Scikit-learn.

И, наконец, в образе может содержаться, поверх всех остальных, ещё один тонкий слой, данные, хранящиеся в котором, поддаются изменению. Это — небольшой по объёму слой, содержащий программу, которую планируется запускать в контейнере.

##### ▍Контейнер Docker

Для того чтобы запустить контейнер, нам нужен, во-первых, образ контейнера, во-вторых — среда, в которой установлен Docker, способная понять команду вида `docker run image_name`. Эта команда создаёт контейнер из образа и запускает его.

##### ▍Репозиторий контейнеров

Если вы хотите дать возможность другим людям создавать контейнеры на основе вашего образа, вы можете отправить этот образ в облачное хранилище. Самым крупным подобным хранилищем является репозиторий [Docker Hub](https://hub.docker.com/). Он используется при работе с Docker по умолчанию.

Мы уже довольно много всего обсудили. Пришло время собрать всё это вместе и сравнить работу с контейнерами Docker с приготовлением пиццы.

#### Готовим с Docker

- Рецепт приготовления пиццы — это файл *Dockerfile*. Он сообщает нам о том, что нужно сделать для того, чтобы достичь цели, то есть — получить работающий контейнер.
- Ингредиенты, из которых состоит пицца — это слои образа контейнера. Для нашей пиццы понадобится корж, соус и сыр.

Если положить на стол рецепт и ингредиенты, то получится, что в одном месте собрано всё, что нужно для того, чтобы приготовить пиццу. Это всё можно сравнить с образом контейнера Docker.
Из рецепта (*Dockerfile*) можно узнать о том, какую последовательность действий нужно выполнить для того, чтобы приготовить пиццу:

- Корж уже готов к использованию, мы его не меняем. Его можно сравнить с базовым образом ОС Ubuntu. Это — нижний слой образа, его в образ добавляют первым.
- Затем на корж добавляют сыр. Это — всё равно что добавить в образ второй слой в виде какой-то внешней библиотеки наподобие NumPy.
- Затем, поверх сыра, добавляют соус. Это — код приложения, которое должно запускаться в контейнере.

Теперь пришло время готовить пиццу в духовке.

Духовка, в которой готовится пицца, напоминает платформу Docker. Духовку устанавливают на кухне, с её помощью можно готовить еду. Точно так же Docker устанавливают на компьютере для того, чтобы «готовить» контейнеры.

Духовку, если она электрическая, включают, поворачивая ручку регулятора температуры. Команда `docker run image_name` — это нечто вроде такого регулятора температуры, «поворот» которого приводит к тому, что система создаёт и запускает контейнер.

Готовая пицца — это и есть контейнер Docker.

А есть пиццу — значит пользоваться приложением, запущенным в контейнере.

Как и приготовление пиццы, подготовка к работе контейнеров Docker занимает некоторое время, но в финале и в том и в другом случаях получается что-то вкусное.

#### Итоги

Здесь мы, на концептуальном уровне, рассмотрели основы Docker. Надеемся, приведённые здесь сравнения помогли вам разобраться в том, что такое Docker, и ощутить ценность метафор в деле освоения новых технологий.

### Изучаем Docker, часть 2: термины и концепции / Хабр
[67389b575040133e8429e677](https://habr.com/ru/companies/ruvds/articles/439978/)

В первой части перевода серии материалов, посвящённых Docker, мы сделали общий обзор этой системы. В частности, мы говорили о том, почему технологии контейнеризации важны в наше время, о том, что такое контейнеры Docker, и о том, с чем их можно сравнить. Сегодня мы поговорим об экосистеме Docker и рассмотрим важные термины, с которыми вы можете столкнуться на пути изучения и использования Docker. Продолжив аналогию с разными вкусностями, представим, что наши термины — это пончики. Дюжина пончиков.

#### Термины экосистемы Docker

Я разбил термины, с которыми вы можете столкнуться в ходе работы с Docker, на две части. Думаю, это облегчит их запоминание. Первый блок терминов будет относиться к механизмам Docker. Второй — к средствам масштабирования решений, основанных на контейнерах.

#### Механизмы Docker

##### ▍Платформа Docker
<dfn title="платформа Docker">Платформа Docker</dfn> ([Docker Platform](https://docs.docker.com/engine/docker-overview/#the-docker-platform)) — это программа, которая даёт нам возможность упаковывать приложения в контейнеры и запускать их на серверах. Платформа Docker позволяет помещать в контейнеры код и его зависимости. Как результат, системы, основанные на контейнерах, легко масштабировать, так как контейнеры можно переносить и воспроизводить.

##### ▍Движок Docker
<dfn title="движок Docker">Движок Docker</dfn> ([Docker Engine](https://www.docker.com/products/docker-engine)) — это клиент-серверное приложение. Компания Docker разделила движок Docker на два продукта. [Docker Community Edition](https://docs.docker.com/install/) (CE) — это бесплатное ПО, во многом основанное на опенсорсных инструментах.

Вероятно, вы будете пользоваться именно этой версией Docker. [Docker Enterprise](https://www.docker.com/products/docker-enterprise) — это платная версия системы, дающая пользователям дополнительные возможности в области поддержки систем, управления ими и безопасности. Платная версия Docker даёт компании средства, необходимые для её существования.

##### ▍Клиент Docker

![Клиент Docker и другие механизмы экосистемы](./img/cb662057b01093d7d63715d2d54c8429.png "Клиент Docker и другие механизмы экосистемы")

*Клиент Docker и другие механизмы экосистемы (взято из [документации](https://docs.docker.com/engine/docker-overview/))*

Клиент Docker ([Docker Client](https://docs.docker.com/engine/docker-overview/)) — это основное средство, которое используют для взаимодействия с Docker. Так, при работе с интерфейсом командной строки Docker ([Docker Command Line Interface](https://docs.docker.com/engine/reference/commandline/cli/), CLI), в терминал вводят команды, начинающиеся с ключевого слова docker, обращаясь к клиенту. Затем клиент использует API Docker для отправки команд демону Docker.

##### ▍Демон Docker

<dfn title="демон Docker">Демон Docker</dfn> ([Docker Daemon](https://docs.docker.com/engine/docker-overview/)) — это сервер Docker, который ожидает запросов к API Docker. Демон Docker управляет образами, контейнерами, сетями и томами.

##### ▍Тома Docker
Тома Docker ([Docker Volumes](https://docs.docker.com/storage/volumes/)) представляют собой наиболее предпочтительный механизм постоянного хранения данных, потребляемых или производимых приложениями.

##### ▍Реестр Docker

<dfn title="реестр Docker">Реестр Docker</dfn> ([Docker Registry](https://hub.docker.com/)) представляет собой удалённую платформу, используемую для хранения образов Docker. В ходе работы с Docker образы отправляют в реестр и загружают из него. Подобный реестр может быть организован тем, кто пользуется Docker. Кроме того, поставщики облачных услуг могут поддерживать и собственные реестры. Например, это касается [AWS](https://aws.amazon.com/ecr/) и [Google Cloud](https://cloud.google.com/container-registry/).

##### ▍Хаб Docker

<dfn title="хаб Docker">Хаб Docker</dfn> ([Docker Hub](https://hub.docker.com/)) — это самый крупный реестр образов Docker. Кроме того, именно этот реестр используется при работе с Docker по умолчанию. Пользоваться хабом Docker можно бесплатно.

##### ▍Репозиторий Docker

<dfn title="репозиторий docker">Репозиторием Docker</dfn> ([Docker Repository](https://docs.docker.com/docker-hub/repos/)) называют набор образов Docker, обладающих одинаковыми именами и разными тегами. Теги — это идентификаторы образов.

Обычно в репозиториях хранятся разные версии одних и тех же образов. Например, [Python](https://hub.docker.com/_/python) — это имя популярнейшего официального репозитория Docker на хабе Docker. А вот Python:3.7-slim — это версия образа с тегом 3.7-slim в репозитории Python. В реестр можно отправить как целый репозиторий, так и отдельный образ.

Теперь поговорим о терминах экосистемы Docker, имеющих отношение к масштабированию.

#### Масштабирование решений, основанных на контейнерах

Следующие четыре термина имеют отношение к одновременному использованию нескольких контейнеров.

##### ▍Сеть Docker

![Сеть Docker](./img/d4536a49030b09ebbe0adb09ec4e0598.png "Сеть Docker")

*Сеть Docker (взято из [документации](https://docs.docker.com/engine/tutorials/networkingcontainers/))*

Сетевые механизмы Docker ([Docker Networking](https://docs.docker.com/engine/tutorials/networkingcontainers/)) позволяют организовывать связь между контейнерами Docker. Соединённые с помощью сети контейнеры могут выполняться на одном и том же хосте или на разных хостах. Подробности о сетевой подсистеме Docker можно почитать [здесь](https://www.oreilly.com/learning/what-is-docker-networking).

##### ▍Docker Compose

[Docker Compose](https://docs.docker.com/compose/) — это инструмент, который упрощает развёртывание приложений, для работы которых требуется несколько контейнеров Docker. Docker Compose позволяет выполнять команды, описываемые в файле *docker-compose.yml*. Эти команды можно выполнять столько раз, сколько потребуется. Интерфейс командной строки Docker Compose упрощает взаимодействие с многоконтейнерными приложениями. Этот инструмент устанавливается при установке Docker.

##### ▍Docker Swarm

[Docker Swarm](https://docs.docker.com/engine/swarm/) — это решение, предназначенное для управления контейнерными развёртываниями (то есть, как говорят, для оркестрации контейнеров). В [этом](https://docs.docker.com/get-started/#recap-and-cheat-sheet) материале из официального учебного курса по Docker можно найти сведения о Docker Swarm. Мне хотелось бы порекомендовать вам не тратить время на изучение Docker Swarm в том случае, если у вас нет на то веской причины.

##### ▍Сервисы Docker

<dfn title="сервис Docker">Сервисы Docker</dfn> ([Docker Services](https://docs.docker.com/get-started/part3/#introduction)) — это различные части распределённого приложения. Вот что о них говорится в [документации](https://docs.docker.com/get-started/part3/#introduction):

> Сервисы — это всего лишь «контейнеры в продакшне». В пределах сервиса выполняется лишь один образ, но сервис определяет то, как именно выполняется образ. В частности, речь идёт о том, какие порты должны использоваться, сколько реплик контейнера должно выполняться для того, чтобы сервис обеспечивал бы необходимую вычислительную мощность, и так далее. Масштабирование сервисов предусматривает изменение количества экземпляров контейнера, в которых работает некая программа, благодаря чему сервису выделяется столько системных ресурсов, сколько ему требуется для решения некоей задачи.

Сервисы Docker позволяют масштабировать контейнеры в пределах нескольких демонов Docker, благодаря им существует и технология Docker Swarm.

#### Краткий перечень терминов

Давайте, буквально в двух словах, повторим только что представленные вам термины:

Механизмы Docker:

1. Платформа Docker — ПО, благодаря которому можно работать с контейнерами.
2. Движок Docker — клиент-серверное приложение (CE или Enterprise).
3. Клиент Docker — программа, которая позволяет взаимодействовать с демоном Docker посредством CLI.
4. Демон Docker — сервер Docker, отвечающий за управление ключевыми механизмами системы.
5. Тома Docker — хранилище информации, используемое в контейнерах.
6. Реестр Docker — удалённое хранилище образов.
7. Хаб Docker — самый крупный реестр Docker, используемый по умолчанию.
8. Репозиторий — коллекция образов Docker с одним и тем же именем.

Масштабирование:

1. Сетевая подсистема Docker — среда, которая позволяет организовывать взаимодействие контейнеров.
2. Docker Compose — технология, упрощающая работу с многоконтейнерными приложениями.
3. Docker Swarm — средство для управления развёртыванием контейнеров.
4. Сервисы Docker — контейнеры в продакшне.

Выше мы говорили о том, что рассмотрим дюжину терминов экосистемы Docker, сравнивая их с дюжиной пончиков. Мы рассмотрели уже 12 терминов, и, казалось бы, на этом можно и остановиться. Но мы, [на всякий случай](https://www.britannica.com/story/why-is-a-bakers-dozen-13), добавим в наш список ещё один термин.

Этот термин относится не к самой платформе Docker, а к технологии, которая очень часто используется совместно с Docker.

#### Kubernetes
[Kubernetes](https://kubernetes.io/) — это технология, которая позволяет автоматизировать развёртывание и масштабирование контейнеризированных приложений, а также управление ими. Это — бесспорный лидер рынка средств для оркестрации контейнеров. Если вам нужен инструмент для работы с группами контейнеров, для масштабирования решений, основанных на них, используйте не Docker Swarm, а Kubernetes. Kubernetes не является частью Docker. Они с Docker, скорее, похожи на лучших друзей.

Теперь, когда вы ознакомились с общими понятиями Docker и с терминологией, вы можете приступить к практическим экспериментам.

#### Итоги: печём пончики с Docker

Помните, как в прошлый раз мы сравнивали платформу Docker с духовкой, которую устанавливают в кухне? Сейчас самое время установить Docker на вашей «кухне» и что-нибудь приготовить.

Docker можно запускать локально на Linux, Mac и Windows. Если вы пользуетесь Mac или Windows, вы можете установить свежую версию Docker Desktop [отсюда](https://www.docker.com/products/docker-desktop). Вместе с этой программой, кстати, устанавливается и Kubernetes. Если вы устанавливаете Docker на другой платформе, то загляните [сюда](https://docs.docker.com/install/) для того, чтобы найти подходящую версию.

После установки Docker взгляните на первые две части [официального руководства](https://docs.docker.com/get-started/).

В следующий раз мы продолжим разговор о Docker. В частности, поговорим о файлах Dockerfile.

### Изучаем Docker, часть 3: файлы Dockerfile / Хабр
[6738d6cd5040133e8429e681](https://habr.com/ru/companies/ruvds/articles/439980/)

В переводе третьей части серии материалов, посвящённых Docker, мы продолжим вдохновляться выпечкой, а именно — бубликами. Нашей сегодняшней основной темой будет работа с файлами Dockerfile. Мы разберём инструкции, которые используются в этих файлах.

#### Образы Docker

Вспомните о том, что контейнер Docker — это образ Docker, вызванный к жизни. Это — самодостаточная операционная система, в которой имеется только самое необходимое и код приложения.

Образы Docker являются результатом процесса их сборки, а контейнеры Docker — это выполняющиеся образы. В самом сердце Docker находятся файлы Dockerfile. Подобные файлы сообщают Docker о том, как собирать образы, на основе которых создаются контейнеры.

Каждому образу Docker соответствует файл, который называется Dockerfile. Его имя записывается именно так — без расширения. При запуске команды `docker build` для создания нового образа подразумевается, что Dockerfile находится в текущей рабочей директории. Если этот файл находится в каком-то другом месте, его расположение можно указать с использованием флага `-f`.

Контейнеры, как мы выяснили в первом материале этой серии, состоят из слоёв. Каждый слой, кроме последнего, находящегося поверх всех остальных, предназначен только для чтения. Dockerfile сообщает системе Docker о том, какие слои и в каком порядке надо добавить в образ.

Каждый слой, на самом деле, это всего лишь файл, который описывает изменение состояния образа в сравнении с тем состоянием, в котором он пребывал после добавления предыдущего слоя. В Unix, кстати, практически всё что угодно — это [файл](https://en.wikipedia.org/wiki/Everything_is_a_file).

<dfn title="базовый образ">Базовый образ</dfn> — это то, что является исходным слоем (или слоями) создаваемого образа. Базовый образ ещё называют родительским образом.

Когда образ загружается из удалённого репозитория на локальный компьютер, то физически скачиваются лишь слои, которых на этом компьютере нет. Docker стремится экономить пространство и время путём повторного использования существующих слоёв.

#### Файлы Dockerfile

В файлах Dockerfile содержатся инструкции по созданию образа. С них, набранных заглавными буквами, начинаются строки этого файла. После инструкций идут их аргументы. Инструкции, при сборке образа, обрабатываются сверху вниз. Вот как это выглядит:
```docker
FROM ubuntu:18.04
COPY . /app
```

Слои в итоговом образе создают только инструкции `FROM`, `RUN`, `COPY`, и `ADD`. Другие инструкции что-то настраивают, описывают метаданные, или сообщают Docker о том, что во время выполнения контейнера нужно что-то сделать, например — открыть какой-то порт или выполнить какую-то команду.

Здесь мы исходим из предположения, в соответствии с которым используется образ Docker, основанный на Unix-подобной ОС. Конечно, тут можно воспользоваться и образом, основанным на Windows, но использование Windows — это менее распространённая практика, работать с такими образами сложнее. В результате, если у вас есть такая возможность, пользуйтесь Unix.

Для начала приведём список инструкций Dockerfile с краткими комментариями.

#### Дюжина инструкций Dockerfile

1. `FROM` — задаёт базовый (родительский) образ.
2. `LABEL` — описывает метаданные. Например — сведения о том, кто создал и поддерживает образ.
3. `ENV` — устанавливает постоянные переменные среды.
4. `RUN` — выполняет команду и создаёт слой образа. Используется для установки в контейнер пакетов.
5. `COPY` — копирует в контейнер файлы и папки.
6. `ADD` — копирует файлы и папки в контейнер, может распаковывать локальные *.tar*-файлы.
7. `CMD` — описывает команду с аргументами, которую нужно выполнить когда контейнер будет запущен. Аргументы могут быть переопределены при запуске контейнера. В файле может присутствовать лишь одна инструкция CMD.
8. `WORKDIR` — задаёт рабочую директорию для следующей инструкции.
9. `ARG` — задаёт переменные для передачи Docker во время сборки образа.
10. `ENTRYPOINT` — предоставляет команду с аргументами для вызова во время выполнения контейнера. Аргументы не переопределяются.
11. `EXPOSE` — указывает на необходимость открыть порт.
12. `VOLUME` — создаёт точку монтирования для работы с постоянным хранилищем.

Теперь поговорим об этих инструкциях.

#### Инструкции и примеры их использования

##### ▍Простой Dockerfile

Dockerfile может быть чрезвычайно простым и коротким. Например — таким:
```docker
FROM ubuntu:18.04
```

##### ▍Инструкция `FROM`

Файл Dockerfile должен начинаться с инструкции `FROM`, или с инструкции `ARG`, за которой идёт инструкция `FROM`.

Ключевое слово [`FROM`](https://docs.docker.com/engine/reference/builder/#from) сообщает Docker о том, чтобы при сборке образа использовался бы базовый образ, который соответствует предоставленному имени и тегу. Базовый образ, кроме того, ещё называют [родительским образом](https://docs.docker.com/develop/develop-images/baseimages/).

В этом примере базовый образ хранится в репозитории [ubuntu](https://hub.docker.com/_/ubuntu). Ubuntu — это название официального репозитория Docker, предоставляющего базовую версию популярной ОС семейства Linux, которая называется Ubuntu.

Обратите внимание на то, что рассматриваемый Dockerfile включает в себя тег `18.04`, уточняющий то, какой именно базовый образ нам нужен. Именно этот образ и будет загружен при сборке нашего образа. Если тег в инструкцию не включён, тогда Docker исходит из предположения о том, что требуется самый свежий образ из репозитория. Для того чтобы яснее выразить свои намерения, автору Dockerfile рекомендуется указывать то, какой именно образ ему нужен.

Когда вышеописанный Dockerfile используется на локальной машине для сборки образа в первый раз, Docker загрузит слои, определяемые образом `ubuntu`. Их можно представить наложенными друг на друга. Каждый следующий слой представляет собой файл, описывающий отличия образа в сравнении с тем его состоянием, в котором он был после добавления в него предыдущего слоя.

При создании контейнера слой, в который можно вносить изменения, добавляется поверх всех остальных слоёв. Данные, находящиеся в остальных слоях, можно только читать.

![Структура контейнера](./img/912530d4f3468f0bff2a064d58d62caf.jpg "Структура контейнера")

*Структура контейнера (взято из [документации](https://docs.docker.com/v17.09/engine/userguide/storagedriver/imagesandcontainers/#images-and-layers))*

Docker, ради эффективности, использует стратегию копирования при записи. Если слой в образе существует на предыдущем уровне и какому-то слою нужно произвести чтение данных из него, Docker использует существующий файл. При этом ничего загружать не нужно.

Когда образ выполняется, если слой нужно модифицировать средствами контейнера, то соответствующий файл копируется в самый верхний, изменяемый слой. Для того чтобы узнать подробности о стратегии копирования при записи, взгляните на [этот](https://docs.docker.com/v17.09/engine/userguide/storagedriver/imagesandcontainers/) материал из документации Docker.

Продолжим рассмотрение инструкций, которые используются в Dockerfile, приведя пример такого файла с более сложной структурой.

##### ▍Более сложный Dockerfile

Хотя файл Dockerfile, который мы только что рассмотрели, получился аккуратным и понятным, он устроен слишком просто, в нём используется всего одна инструкция. Кроме того, там нет инструкций, вызываемых во время выполнения контейнера. Взглянем на ещё один файл, который собирает маленький образ. В нём имеются механизмы, определяющие команды, вызываемые во время выполнения контейнера.
```docker
FROM python:3.7.2-alpine3.8
LABEL maintainer="jeffmshale@gmail.com"
ENV ADMIN="jeff"
RUN apk update && apk upgrade && apk add bash
COPY . ./app
ADD https://raw.githubusercontent.com/discdiver/pachy-vid/master/sample_vids/vid1.mp4 \
/my_app_directory
RUN ["mkdir", "/a_directory"]
CMD ["python", "./my_script.py"]
```

Возможно, на первый взгляд этот файл может показаться довольно сложным. Поэтому давайте с ним разберёмся.

Базой этого образа является официальный образ Python с тегом 3.7.2-alpine3.8. Проанализировав этот код можно увидеть, что данный базовый образ включает в себя Linux, Python, и, по большому счёту, этим его состав и ограничивается. Образы ОС Alpine весьма популярны в мире Docker. Дело в том, что они отличаются маленькими размерами, высокой скоростью работы и безопасностью. Однако образы Alpine не отличаются широкими возможностями, характерными для обычных операционных систем. Поэтому для того, чтобы собрать на основе такого образа что-то полезное, создателю образа нужно установить в него необходимые ему пакеты.

##### ▍Инструкция `LABEL`
Инструкция [`LABEL`](https://docs.docker.com/engine/reference/builder/#label) (метка) позволяет добавлять в образ метаданные. В случае с рассматриваемым сейчас файлом, она включает в себя контактные сведения создателя образа. Объявление меток не замедляет процесс сборки образа и не увеличивает его размер. Они лишь содержат в себе полезную информацию об образе Docker, поэтому их рекомендуется включать в файл. Подробности о работе с метаданными в Dockerfile можно прочитать [здесь](https://docs.docker.com/config/labels-custom-metadata/).

##### ▍Инструкция `ENV`
Инструкция [`ENV`](https://docs.docker.com/engine/reference/builder/#env) позволяет задавать постоянные переменные среды, которые будут доступны в контейнере во время его выполнения. В предыдущем примере после создания контейнера можно пользоваться переменной `ADMIN`.

Инструкция `ENV` хорошо подходит для задания констант. Если вы используете некое значение в Dockerfile несколько раз, скажем, при описании команд, выполняющихся в контейнере, и подозреваете, что, возможно, вам когда-нибудь придётся сменить его на другое, его имеет смысл записать в подобную константу.

Надо отметить, что в файлах Dockerfile часто существуют разные способы решения одних и тех же задач. Что именно использовать — это вопрос, на решение которого влияет стремление к соблюдению принятых в среде Docker методов работы, к обеспечению прозрачности решения и его высокой производительности. Например, инструкции `RUN`, `CMD` и `ENTRYPOINT` служат разным целям, но все они используются для выполнения команд.

##### ▍Инструкция `RUN`
Инструкция [`RUN`](https://docs.docker.com/engine/reference/builder/#run) позволяет создать слой во время сборки образа. После её выполнения в образ добавляется новый слой, его состояние фиксируется. Инструкция `RUN` часто используется для установки в образы дополнительных пакетов. В предыдущем примере инструкция `RUN apk update && apk upgrade` сообщает Docker о том, что системе нужно обновить пакеты из базового образа. Вслед за этими двумя командами идёт команда `&& apk add bash`, указывающая на то, что в образ нужно установить bash.

То, что в командах выглядит как `apk` — это сокращение от [Alpine Linux package manager](https://www.cyberciti.biz/faq/10-alpine-linux-apk-command-examples/) (менеджер пакетов Alpine Linux). Если вы используете базовый образ какой-то другой ОС семейства Linux, тогда вам, например, при использовании Ubuntu, для установки пакетов может понадобиться команда вида `RUN apt-get`. Позже мы поговорим о других способах установки пакетов.

Инструкция `RUN` и схожие с ней инструкции — такие, как `CMD` и `ENTRYPOINT`, могут быть использованы либо в exec-форме, либо в shell-форме. Exec-форма использует синтаксис, напоминающий описание JSON-массива. Например, это может выглядеть так: `RUN ["my_executable", "my_first_param1", "my_second_param2"]`.

В предыдущем примере мы использовали shell-форму инструкции `RUN` в таком виде: `RUN apk update && apk upgrade && apk add bash`.

Позже в нашем Dockerfile использована exec-форма инструкции `RUN`, в виде `RUN ["mkdir", "/a_directory"]` для создания директории. При этом, используя инструкцию в такой форме, нужно помнить о необходимости оформления строк с помощью двойных кавычек, как это принято в формате JSON.

##### ▍Инструкция `COPY`
Инструкция [`COPY`](https://docs.docker.com/engine/reference/builder/#copy) представлена в нашем файле так: `COPY . ./app`. Она сообщает Docker о том, что нужно взять файлы и папки из локального контекста сборки и добавить их в текущую рабочую директорию образа. Если целевая директория не существует, эта инструкция её создаст.

##### ▍Инструкция `ADD`
Инструкция [`ADD`](https://docs.docker.com/engine/reference/builder/#add) позволяет решать те же задачи, что и `COPY`, но с ней связана ещё пара вариантов использования. Так, с помощью этой инструкции можно добавлять в контейнер файлы, загруженные из удалённых источников, а также распаковывать локальные .tar-файлы.

В этом примере инструкция `ADD` была использована для копирования файла, доступного по URL, в директорию контейнера `my_app_directory`. Надо отметить, однако, что [документация Docker](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/) не рекомендует использование подобных файлов, полученных по URL, так как удалить их нельзя, и так как они увеличивают размер образа.

Кроме того, документация предлагает везде, где это возможно, вместо инструкции `ADD` использовать инструкцию `COPY` для того, чтобы сделать файлы Dockerfile понятнее. Полагаю, команде разработчиков Docker стоило бы объединить `ADD` и `COPY` в одну инструкцию для того, чтобы тем, кто создаёт образы, не приходилось бы помнить слишком много инструкций.

Обратите внимание на то, что инструкция `ADD` содержит символ разрыва строки — `\`. Такие символы используются для улучшения читабельности длинных команд путём разбиения их на несколько строк.

##### ▍Инструкция `CMD`
Инструкция [`CMD`](https://docs.docker.com/engine/reference/builder/#cmd) предоставляет Docker команду, которую нужно выполнить при запуске контейнера. Результаты выполнения этой команды не добавляются в образ во время его сборки. В нашем примере с помощью этой команды запускается скрипт `my_script.py` во время выполнения контейнера.

Вот ещё кое-что, что нужно знать об инструкции `CMD`:

- В одном файле Dockerfile может присутствовать лишь одна инструкция `CMD`. Если в файле есть несколько таких инструкций, система проигнорирует все кроме последней.
- Инструкция `CMD` может иметь exec-форму. Если в эту инструкцию не входит упоминание исполняемого файла, тогда в файле должна присутствовать инструкция `ENTRYPOINT`. В таком случае обе эти инструкции должны быть представлены в формате JSON.
- Аргументы командной строки, передаваемые `docker run`, переопределяют аргументы, предоставленные инструкции `CMD` в Dockerfile.

##### ▍Ещё более сложный Dockerfile

Рассмотрим ещё один файл Dockerfile, в котором будут использованы некоторые новые команды.
```docker
FROM python:3.7.2-alpine3.8
LABEL maintainer="jeffmshale@gmail.com"
# Устанавливаем зависимости
RUN apk add --update git
# Задаём текущую рабочую директорию
WORKDIR /usr/src/my_app_directory
# Копируем код из локального контекста в рабочую директорию образа
COPY . .
# Задаём значение по умолчанию для переменной
ARG my_var=my_default_value
# Настраиваем команду, которая должна быть запущена в контейнере во время его выполнения
ENTRYPOINT ["python", "./app/my_script.py", "my_var"]
# Открываем порты
EXPOSE 8000
# Создаём том для хранения данных
VOLUME /my_volume
```

В этом примере, кроме прочего, вы можете видеть комментарии, которые начинаются с символа `#`.

Одно из основных действий, выполняемых средствами Dockerfile — это установка пакетов. Как уже было сказано, существуют различные способы установки пакетов с помощью инструкции `RUN`.

Пакеты в образ Alpine Docker можно устанавливать с помощью `apk`. Для этого, как мы уже говорили, применяется команда вида `RUN apk update && apk upgrade && apk add bash`.

Кроме того, пакеты Python в образ можно устанавливать с помощью [pip](https://pypi.org/project/pip/), [wheel](https://pythonwheels.com/) и [conda](https://medium.com/@chadlagore/conda-environments-with-docker-82cdc9d25754). Если речь идёт не о Python, а о других языках программирования, то при подготовке соответствующих образов могут использоваться и другие менеджеры пакетов.

При этом для того, чтобы установка была бы возможной, нижележащий слой должен предоставить слою, в который выполняется установка пакетов, подходящий менеджер пакетов. Поэтому если вы столкнулись с проблемами при установке пакетов, убедитесь в том, что менеджер пакетов установлен до того, как вы попытаетесь им воспользоваться.

Например, инструкцию `RUN` в Dockerfile можно использовать для установки списка пакетов с помощью `pip`. Если вы так поступаете — объедините все команды в одну инструкцию и разделите её символами разрыва строки с помощью символа `\`. Благодаря такому подходу файлы будут выглядеть аккуратно и это приведёт к добавлению в образ меньшего количества слоёв, чем было бы добавлено при использовании нескольких инструкций `RUN`.

Кроме того, для установки нескольких пакетов можно поступить и по-другому. Их можно перечислить в файле и передать менеджеру пакетов этот файл с помощью `RUN`. Обычно таким файлам дают имя *requirements.txt*.

##### ▍Инструкция `WORKDIR`
Инструкция [`WORKDIR`](https://docs.docker.com/v17.09/engine/reference/builder/#workdir) позволяет изменить рабочую директорию контейнера. С этой директорией работают инструкции `COPY`, `ADD`, `RUN`, `CMD` и `ENTRYPOINT`, идущие за `WORKDIR`. Вот некоторые особенности, касающиеся этой инструкции:

- Лучше устанавливать с помощью `WORKDIR` абсолютные пути к папкам, а не перемещаться по файловой системе с помощью команд `cd` в Dockerfile.
- Инструкция `WORKDIR` автоматически создаёт директорию в том случае, если она не существует.
- Можно использовать несколько инструкций `WORKDIR`. Если таким инструкциям предоставляются относительные пути, то каждая из них меняет текущую рабочую директорию.

##### ▍Инструкция `ARG`
Инструкция [`ARG`](https://docs.docker.com/engine/reference/builder/#arg) позволяет задать переменную, значение которой можно передать из командной строки в образ во время его сборки. Значение для переменной по умолчанию можно представить в Dockerfile. Например: `ARG my_var=my_default_value`.

В отличие от `ENV`-переменных, `ARG`-переменные недоступны во время выполнения контейнера. Однако `ARG`-переменные можно использовать для задания значений по умолчанию для `ENV`-переменных из командной строки в процессе сборки образа. А `ENV`-переменные уже будут доступны в контейнере во время его выполнения. Подробности о такой методике работы с переменными можно почитать [здесь](https://vsupalov.com/docker-build-time-env-values/).

##### ▍Инструкция ENTRYPOINT
Инструкция [`ENTRYPOINT`](https://docs.docker.com/engine/reference/builder/#entrypoint) позволяет задавать команду с аргументами, которая должна выполняться при запуске контейнера. Она похожа на команду `CMD`, но параметры, задаваемые в `ENTRYPOINT`, не перезаписываются в том случае, если контейнер запускают с параметрами командной строки.

Вместо этого аргументы командной строки, передаваемые в конструкции вида `docker run my_image_name`, добавляются к аргументам, задаваемым инструкцией `ENTRYPOINT`. Например, после выполнения команды вида `docker run my_image bash` аргумент `bash` добавится в конец списка аргументов, заданных с помощью `ENTRYPOINT`. Готовя Dockerfile, не забудьте об инструкции `CMD` или `ENTRYPOINT`.

В документации к Docker есть несколько рекомендаций, касающихся того, какую инструкцию, `CMD` или `ENTRYPOINT`, стоит выбрать в качестве инструмента для выполнения команд при запуске контейнера:

- Если при каждом запуске контейнера нужно выполнять одну и ту же команду — используйте `ENTRYPOINT`.
- Если контейнер будет использоваться в роли приложения — используйте `ENTRYPOINT`.
- Если вы знаете, что при запуске контейнера вам понадобится передавать ему аргументы, которые могут перезаписывать аргументы, указанные в Dockerfile, используйте `CMD`.

В нашем примере использование инструкции `ENTRYPOINT ["python", "my_script.py", "my_var"]` приводит к тому, что контейнер, при запуске, запускает Python-скрипт *my_script.py* с аргументом `my_var`. Значение, представленное `my_var`, потом можно использовать в скрипте с помощью [argparse](https://docs.python.org/3/library/argparse.html). Обратите внимание на то, что в Dockerfile переменной `my_var`, до её использования, назначено значение по умолчанию с помощью `ARG`. В результате, если при запуске контейнера ему не передали соответствующее значение, будет применено значение по умолчанию.

Документация Docker рекомендует использовать exec-форму `ENTRYPOINT`: `ENTRYPOINT ["executable", "param1", "param2"]`.

##### ▍Инструкция `EXPOSE`
Инструкция [`EXPOSE`](https://docs.docker.com/engine/reference/builder/#expose) указывает на то, какие порты планируется открыть для того, чтобы через них можно было бы связаться с работающим контейнером. Эта инструкция не открывает порты. Она, скорее, играет роль документации к образу, средством общения того, кто собирает образ, и того, кто запускает контейнер.

Для того чтобы открыть порт (или порты) и настроить перенаправление портов, нужно выполнить команду `docker run` с ключом `-p`. Если использовать ключ в виде `-P` (с заглавной буквой `P`), то открыты будут все порты, указанные в инструкции `EXPOSE`.

##### ▍Инструкция `VOLUME`
Инструкция [`VOLUME`](https://docs.docker.com/engine/reference/builder/#volume) позволяет указать место, которое контейнер будет использовать для постоянного хранения файлов и для работы с такими файлами. Об этом мы ещё поговорим.

#### Итоги

Теперь вы знаете дюжину инструкций, применяемых при создании образов с помощью Dockerfile. Этим список таких инструкций не исчерпывается. В частности, мы не рассмотрели здесь такие инструкции, как `USER`, `ONBUILD`, `STOPSIGNAL`, `SHELL` и `HEALTHCHECK`. [Вот](https://kapeli.com/cheat_sheets/Dockerfile.docset/Contents/Resources/Documents/index) краткий справочник по инструкциям Dockerfile.

Вероятно, файлы Dockerfile — это ключевой компонент экосистемы Docker, работать с которым нужно научиться всем, кто хочет уверенно чувствовать себя в этой среде. Мы ещё вернёмся к разговору о них в следующий раз, когда будем обсуждать способы уменьшения размеров образов.

### Изучаем Docker, часть 4: уменьшение размеров образов и ускорение их сборки / Хабр
[6739128a5040133e8429e688](https://habr.com/ru/companies/ruvds/articles/440658/)

В этой части перевода серии материалов, которая посвящена Docker, мы поговорим о том, как оптимизировать размеры образов и ускорить их сборку. В прошлых материалах мы сравнивали образы Docker с пиццей, термины с пончиками, а инструкции файлов Dockerfile с бубликами. Сегодня же не будет никакой выпечки. Пришло время посидеть на диете.

Для того чтобы разобраться с тем, о чём мы будем тут говорить, вам будет полезно освежить в памяти то, о чём шла речь в [третьей части](#изучаем-docker-часть-3-файлы-dockerfile--хабр) этой серии материалов. А именно, там мы говорили об инструкциях файлов Dockerfile. Знание этих инструкций и тех особенностей Docker, которые мы обсудим сегодня, поможет вам оптимизировать файлы образов Docker.

#### Кэширование

Одной из сильных сторон Docker является кэширование. Благодаря этому механизму ускоряется сборка образов.

При сборке образа Docker проходится по инструкциям файла *Dockerfile*, выполняя их по порядку. В процессе анализа инструкций Docker проверяет собственный кэш на наличие в нём образов, представляющих собой то, что получается на промежуточных этапах сборки других образов. Если подобные образы удаётся найти, то система может ими воспользоваться, не тратя время на их повторное создание.

Если кэш признан недействительным, то инструкция, в ходе выполнения которой это произошло, выполняется, создавая новый слой без использования кэша. То же самое происходит и при выполнении инструкций, которые следуют за ней.

В результате, если в ходе выполнения инструкций из *Dockerfile* оказывается, что базовый образ имеется в кэше, то используется именно этот образ из кэша. Это называется «попаданием кэша». Если же базового образа в кэше нет, то весь процесс сборки образа будет происходить без использования кэша.

Затем следующая инструкция сопоставляется со всеми образами из кэша, в основе которых лежит тот же самый базовый образ, который уже обнаружен в кэше. Каждый кэшированный промежуточный образ проверяется на предмет того, имеется ли в нём то, что было создано такой же инструкцией. Если совпадения найти не удаётся, это называется «промахом кэша» и кэш считается недействительным. То же самое происходит до тех пор, пока не будет обработан весь файл *Dockerfile*.

Большинство новых инструкций просто сравниваются с тем, что уже есть в промежуточных образах. Если системе удаётся найти совпадение, то при сборке используется то, что уже есть в кэше.

Использование кэша способно ускорить сборку образов, но тут есть одна проблема. Например, если в *Dockerfile* обнаруживается инструкция `RUN pip install -r requirements.txt`, то Docker выполняет поиск такой же инструкции в своём локальном кэше промежуточных образов. При этом содержимое старой и новой версий файла *requirements.txt* не сравнивается.

Подобное может приводить к проблемам в том случае, если в *requirements.txt* были добавлены сведения о новых пакетах, после чего, при сборке обновлённого образа, для того, чтобы установить новый набор пакетов, нужно снова выполнить инструкцию `RUN pip install`. Совсем скоро мы поговорим о том, как бороться с этой проблемой.

В отличие от других инструкций Docker, при выполнении инструкций `ADD` и `COPY` от Docker требуется проверка содержимого файла или файлов для определения того, можно ли, при формировании образа, воспользоваться кэшем. А именно, контрольная сумма файлов, упомянутых в этих инструкциях, сравнивается с контрольной суммой файлов, которые имеются в промежуточных образах, которые уже есть в кэше. Если изменилось содержимое файлов или их метаданные, тогда кэш признаётся недействительным.

Вот несколько советов, касающихся эффективного использования кэша Docker:

- Кэширование можно отключить, передав ключ `--no-cache=True` команде `docker build`.
- Если вы собираетесь вносить изменения в инструкции *Dockerfile*, тогда каждый слой, созданный инструкциями, идущими после изменённых, будет достаточно часто собираться повторно, без использования кэша. Для того чтобы воспользоваться преимуществами кэширования, помещайте инструкции, вероятность изменения которых высока, как можно ближе к концу *Dockerfile*.
- Объединяйте команды `RUN apt-get update` и `apt-get install` в цепочки для того, чтобы исключить проблемы, связанные с неправильным использованием кэша.
- Если вы используете менеджеры пакетов, наподобие `pip`, с файлом *requirements.txt*, тогда придерживайтесь нижеприведённой схемы работы для того, чтобы исключить использование устаревших промежуточных образов из кэша, содержащих набор пакетов, перечисленных в старой версии файла *requirements.txt*. Вот как это выглядит:
```docker
COPY requirements.txt /tmp/
RUN pip install -r /tmp/requirements.txt
COPY . /tmp/
```

Если вам известны другие способы борьбы с «проблемой requirements.txt» — можете рассказать о них в комментариях.

#### Уменьшение размеров образов

##### ▍Тщательный подбор базового образа

Образы Docker могут быть довольно большими. Это противоречит вполне обоснованному стремлению того, кто их создаёт, к тому, чтобы сделать их как можно более компактными, что облегчит их загрузку из удалённого репозитория и благотворно скажется на объёме свободного места на компьютере, на который они загружаются. Поговорим о том, как уменьшать их размеры.

Одним из способов уменьшения размеров образов является тщательный подбор базовых образов и их последующая настройка.

Так, например, базовый образ Alpine представляет собой полноценный дистрибутив Linux-подобной ОС, содержащий минимум дополнительных пакетов. Его размер — примерно 5 мегабайт. Однако сборка собственного образа на основе Alpine потребует потратить достаточно много времени на то, чтобы оснастить его всем необходимым для обеспечения работы некоего приложения.

Существуют и специализированные варианты базового образа Alpine. Например, соответствующий образ из репозитория python, в который упакован скрипт `print("hello world")` весит около 78.5 Мб. Вот *Dockerfile* для сборки такого образа:
```docker
FROM python:3.7.2-alpine3.8
COPY . /app
ENTRYPOINT ["python", "./app/my_script.py", "my_var"]
```

При этом на Docker Hub сказано, что этот базовый образ имеет размер 29 Мб. Размер образа, основанного на этом базовом образе, увеличивается за счёт загрузки и установки Python.

Помимо использования базовых образов, основанных на Alpine, уменьшить размеры образов можно благодаря использованию технологии многоступенчатой сборки.

##### ▍Многоступенчатая сборка образов

В *Dockerfile*, описывающем многоступенчатую сборку образа, используется несколько инструкций `FROM`. Создатель такого образа может настроить выборочное копирование файлов, называемых артефактами сборки, из одной ступени сборки в другую ступень. При этом появляется возможность избавиться от всего того, что в готовом образе не понадобится. Благодаря этому методу можно уменьшить размер готового образа.

Вот как работает каждая инструкция `FROM`:

- Она начинает новый шаг сборки.
- Она не зависит от того, что было создано на предыдущем шаге сборки.
- Она может использовать базовый образ, отличающийся от того, который применялся на предыдущем шаге.

Вот модифицированный пример файла *Dockerfile* из [документации](https://docs.docker.com/develop/develop-images/multistage-build/) Docker, описывающего многоступенчатую сборку.

```docker
FROM golang:1.7.3 AS build
WORKDIR /go/src/github.com/alexellis/href-counter/
RUN go get -d -v golang.org/x/net/html
COPY app.go .
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .
FROM alpine:latest
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=build /go/src/github.com/alexellis/href-counter/app .
CMD ["./app"]
```

Обратите внимание на то, что мы дали имя первой ступени сборки, указав его после инструкции FROM. К именованному этапу сборки мы обращаемся в инструкции `COPY --from=` ниже в Dockerfile.

Применение процесса многоступенчатой сборки образов имеет смысл в некоторых случаях, когда приходится создавать множество контейнеров для продакшн-окружения. Многоступенчатая сборка позволяет максимально сократить размеры готовых образов. Но иногда такой подход приводит к усложнению поддержки образов. Поэтому вы, вероятно, не будете пользоваться многоступенчатой сборкой образов в тех случаях, в которых без неё можно обойтись. Об особенностях этой технологии можно почитать [здесь](https://blog.realkinetic.com/building-minimal-docker-containers-for-python-applications-37d0272c52f3) и [здесь](https://medium.com/@tonistiigi/advanced-multi-stage-build-patterns-6f741b852fae).

Как видите, многоступенчатая сборка — технология интересная, но подходит она далеко не для всех случаев. Тот же способ уменьшения размера образов, который мы обсудим ниже, можно порекомендовать абсолютно всем.

##### ▍Файл .dockerignore

О файлах *.dockerignore* нужно знать абсолютно всем, кто хочет освоить Docker. Эти файлы похожи на файлы *.gitignore*. Они содержат список файлов и папок, в виде имён или шаблонов, которые Docker должен игнорировать в ходе сборки образа.

Этот файл размещают там же, где находится файл *Dockerfile*, и всё остальное, входящее в контекст сборки образа.

При запуске команды `docker build`, инициирующей сборку образа, Docker проверяет папку на наличие в ней файла *.dockerignore*. Если такой файл найти удаётся, тогда этот файл разбирается, при этом при определении списка файлов, которые нужно игнорировать, используются [правила](https://golang.org/pkg/path/filepath/#Match) функции `Match()` из пакета `filepath` Go и некоторые собственные [правила](https://docs.docker.com/v17.09/engine/reference/builder/#dockerignore-file) Docker.

Так, например, если в файле *.dockerignore* встретится шаблон вида `*.jpg`, то при создании образа проигнорированы будут файлы с любым именем и с расширением `.jpg`. Если в файле встретится строка `videos`, то система проигнорирует папку *videos* и всё её содержимое.

При составлении файла *.dockerignore* его можно снабжать комментариями, используя символ `#`.

Вот что даёт тому, кто занимается созданием образов Docker, применение файлов *.dockerignore*:

- Это позволяет исключать из состава образа файлы, содержащие секретные сведения наподобие логинов и паролей.
- Это позволяет уменьшить размер образа. Чем меньше в образе файлов — тем меньше будет его размер и тем быстрее с ним можно будет работать.
- Это даёт возможность уменьшить число поводов для признания недействительным кэша при сборке похожих образов. Например, если при повторной сборке образа меняются некие служебные файлы проекта, наподобие файлов с журналами, из-за чего данные, хранящиеся в кэше, по сути, необоснованно признаются недействительными, это замедляет сборку образов.

Подробности о файле *.dockerignore* можно почитать в [документации](https://docs.docker.com/v17.09/engine/reference/builder/#dockerignore-file) к Docker.

#### Исследование размеров образов

Поговорим о том, как, пользуясь средствами командной строки, узнавать размеры образов и контейнеров Docker.

- Для того чтобы выяснить примерный размер выполняющегося контейнера, можно использовать команду вида `docker container ls -s`.
- Команда `docker image ls` выводит размеры образов.
- Узнать размеры промежуточных образов, из которых собран некий образ, можно с помощью команды `docker image history my_image:my_tag`.
- Команда `docker image inspect my_image:tag` позволяет узнать подробные сведения об образе, в том числе — размер каждого его слоя. Слои немного отличаются от промежуточных образов, из которых состоит готовый образ, но, в большинстве случаев их можно рассматривать как одинаковые сущности. [Вот](https://windsock.io/explaining-docker-image-ids/) хороший материал, который посвящён подробностям внутреннего устройства образов Docker.
- Для того чтобы исследовать содержимое контейнеров можно установить пакет [dive](https://github.com/wagoodman/dive).

Теперь, когда мы обсудили возможности по уменьшению размеров образов, предлагаю вашему вниманию восемь рекомендаций, касающихся уменьшения размеров образов и ускорения процесса их сборки.

#### Рекомендации по уменьшению размеров образов и ускорению процесса их сборки

1. Используйте всегда, когда это возможно, официальные образы в качестве базовых образов. Официальные образы регулярно обновляются, они безопаснее неофициальных образов.
2. Для того чтобы собирать как можно более компактные образы, пользуйтесь базовыми образами, основанными на Alpine Linux.
3. Если вы пользуетесь `apt`, комбинируйте в одной инструкции `RUN` команды `apt-get update` и `apt-get install`. Кроме того, объединяйте в одну инструкцию команды установки пакетов. Перечисляйте пакеты в алфавитном порядке на нескольких строках, разделяя список символами `\.` Например, это может выглядеть так:
    ```docker
    RUN apt-get update && apt-get install -y \
        package-one \
        package-two \
        package-three
    && rm -rf /var/lib/apt/lists/*
    ```

    Этот метод позволяет сократить число слоёв, которые должны быть добавлены в образ, и помогает поддерживать код файла в приличном виде.
4. Включайте конструкцию вида `&& rm -rf /var/lib/apt/lists/*` в конец инструкции `RUN`, используемой для установки пакетов. Это позволит очистить кэш `apt` и приведёт к тому, что он не будет сохраняться в слое, сформированном командой `RUN`. Подробности об этом можно почитать в [документации](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/).
5. Разумно пользуйтесь возможностями кэширования, размещая в *Dockerfile* команды, вероятность изменения которых высока, ближе к концу файла.
6. Пользуйтесь файлом *.dockerignore*.
7. Взгляните на `dive` — отличный инструмент для исследования образов Docker, который помогает в деле уменьшения их размеров.
8. Не устанавливайте в образы пакеты, без которых можно обойтись.

#### Итоги

Теперь вы знаете о том, как сделать так, чтобы образы Docker быстро собирались бы, быстро загружались бы из репозиториев и не занимали бы слишком много места на компьютере. В следующий раз мы поговорим о командах Docker.
